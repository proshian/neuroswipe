{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import copy\n",
    "from multiprocessing import cpu_count\n",
    "from typing import List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from model import SwipeCurveTransformer, get_m1_model, get_m1_bigger_model, get_m1_smaller_model\n",
    "from tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n",
    "from dataset import NeuroSwipeDatasetv2, NeuroSwipeGridSubset\n",
    "from word_generators import GreedyGenerator, BeamGenerator\n",
    "from word_generation_v2 import predict_raw_mp\n",
    "from metrics import get_mmr\n",
    "from get_individual_models_predictions import weights_to_raw_predictions\n",
    "from aggregate_predictions import (separate_out_vocab_all_crvs,\n",
    "                                   append_preds,\n",
    "                                   create_submission,\n",
    "                                   merge_default_and_extra_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_KAGGLE = False\n",
    "\n",
    "if IN_KAGGLE:\n",
    "    DATA_ROOT = \"/kaggle/input/yandex-cup-playground\"\n",
    "    MODELS_DIR = \"\"\n",
    "else:\n",
    "    DATA_ROOT = \"../data/data_separated_grid\"\n",
    "    MODELS_ROOT = \"../data/trained_models\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_grid(grid_name: str, grids_path: str) -> dict:\n",
    "    with open(grids_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return json.load(f)[grid_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:02<00:00, 4816.94it/s]\n",
      "100%|██████████| 10000/10000 [00:01<00:00, 5583.61it/s]\n"
     ]
    }
   ],
   "source": [
    "MAX_TRAJ_LEN = 299\n",
    "\n",
    "grid_name_to_grid_path = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n",
    "grid_name_to_grid = {grid_name: get_grid(grid_name, grid_name_to_grid_path) for grid_name in (\"default\", \"extra\")}\n",
    "\n",
    "\n",
    "kb_tokenizer = KeyboardTokenizerv1()\n",
    "word_char_tokenizer = CharLevelTokenizerv2(os.path.join(DATA_ROOT, \"voc.txt\"))\n",
    "keyboard_selection_set = set(kb_tokenizer.i2t)\n",
    "\n",
    "\n",
    "val_path = os.path.join(DATA_ROOT, \"valid__in_train_format.jsonl\")\n",
    "\n",
    "\n",
    "val_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = val_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=True,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")\n",
    "\n",
    "test_path = os.path.join(DATA_ROOT, \"test.jsonl\")\n",
    "\n",
    "\n",
    "test_dataset = NeuroSwipeDatasetv2(\n",
    "    data_path = test_path,\n",
    "    gridname_to_grid = grid_name_to_grid,\n",
    "    kb_tokenizer = kb_tokenizer,\n",
    "    max_traj_len = MAX_TRAJ_LEN,\n",
    "    word_tokenizer = word_char_tokenizer,\n",
    "    include_time = False,\n",
    "    include_velocities = True,\n",
    "    include_accelerations = True,\n",
    "    has_target=False,\n",
    "    has_one_grid_only=False,\n",
    "    include_grid_name=True,\n",
    "    keyboard_selection_set=keyboard_selection_set,\n",
    "    total = 10_000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_dataset = NeuroSwipeGridSubset(val_dataset, \"default\")\n",
    "val_extra_dataset = NeuroSwipeGridSubset(val_dataset, \"extra\")\n",
    "\n",
    "test_default_dataset = NeuroSwipeGridSubset(test_dataset, \"default\")\n",
    "test_extra_dataset = NeuroSwipeGridSubset(test_dataset, \"extra\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_targets(dataset: NeuroSwipeDatasetv2) -> List[str]:\n",
    "    targets = []\n",
    "    for (_, _, _, _, word_pad_mask), target_tokens, _ in dataset:\n",
    "        target_len = int(torch.sum(~word_pad_mask)) - 1\n",
    "        target = word_char_tokenizer.decode(target_tokens[:target_len])\n",
    "        targets.append(target)\n",
    "    return targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocab_set(vocab_path: str):\n",
    "    with open(vocab_path, 'r', encoding = \"utf-8\") as f:\n",
    "        return set(f.read().splitlines())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = get_vocab_set(os.path.join(DATA_ROOT, \"voc.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cpu')\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = get_m1_smaller_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_smaller/m1_smaller_v2_2023_11_11_17_43_35_0_33179_default_l2_1e_05_ls0_02.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target               prediction           prob                \n",
      "-------------------------------------------------\n",
      "на                   на                   0.95232             \n",
      "все                  все                  0.94362             \n",
      "добрый               добрый               0.90555             \n",
      "девочка              девочка              0.87215             \n",
      "сказала              сказала              0.90086             \n",
      "скинь                скинь                0.92264             \n",
      "геев                 гееев                0.25355             \n",
      "тобой                тобой                0.91465             \n",
      "была                 быса                 0.66717             \n",
      "да                   да                   0.95149             \n",
      "муж                  мад                  0.18687             \n",
      "щас                  щас                  0.94379             \n",
      "она                  она                  0.93583             \n",
      "проблема             проблема             0.85841             \n",
      "билайн               билайн               0.68792             \n",
      "уже                  уже                  0.94623             \n",
      "раньше               раньше               0.88046             \n",
      "рам                  рам                  0.50038             \n",
      "щас                  щас                  0.95931             \n",
      "купил                купил                0.90516             \n",
      "ты                   ты                   0.95519             \n",
      "зовут                зовут                0.91101             \n",
      "короче               короче               0.91912             \n",
      "размыто              размыто              0.44183             \n",
      "давай                давай                0.90277             \n",
      "отдать               отдать               0.66945             \n",
      "привет               привет               0.91289             \n",
      "не                   не                   0.94382             \n",
      "да                   да                   0.95367             \n",
      "будете               будете               0.90258             \n",
      "связи                связи                0.90730             \n",
      "колывань             колываешь            0.20803             \n",
      "меня                 меня                 0.93267             \n",
      "напиши               напиши               0.90677             \n",
      "знаю                 знаю                 0.94301             \n",
      "мамой                мамой                0.89931             \n",
      "не                   не                   0.94824             \n",
      "ты                   ты                   0.95712             \n",
      "только               только               0.90712             \n",
      "они                  они                  0.94032             \n",
      "свинг                свинг                0.64798             \n"
     ]
    }
   ],
   "source": [
    "greedy_generator = GreedyGenerator(model, word_char_tokenizer, device)\n",
    "\n",
    "\n",
    "print(\"{:<20} {:<20} {:<20}\".format(\"target\", \"prediction\", \"prob\"))\n",
    "# print(\"-\"*31)\n",
    "print(\"-\"*49)\n",
    "\n",
    "n_examples = 40\n",
    "\n",
    "for i, data in enumerate(val_default_dataset):\n",
    "\n",
    "    (xyt, kb_tokens, dec_in_char_seq, traj_pad_mask, word_pad_mask), target, grid_name = data\n",
    "\n",
    "    score, pred = greedy_generator(xyt, kb_tokens, traj_pad_mask)[0]\n",
    "\n",
    "    # strip работвет только потому что в настоящих словах нет этих символов\n",
    "    pred = pred\n",
    "    target_len = int(torch.sum(~word_pad_mask)) - 1\n",
    "    target = word_char_tokenizer.decode(target[:target_len])\n",
    "    print(\"{:<20} {:<20} {:<20.5f}\".format(target, pred, np.exp(score)))\n",
    "\n",
    "    if i >= n_examples:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_targets = get_targets(val_default_dataset)\n",
    "val_extra_targets = get_targets(val_extra_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate models separately and as a pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "print(cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_default_targets = get_targets(val_default_dataset)\n",
    "val_extra_targets = get_targets(val_extra_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_predictions = weights_to_raw_predictions(\n",
    "    grid_name = \"default\",\n",
    "    model_getter=get_m1_bigger_model,\n",
    "    weights_path = os.path.join(MODELS_ROOT, \"m1_bigger/m1_bigger_v2__2023_11_12__12_30_29__0.13121__greed_acc_0.86098__default_l2_0_ls0_switch_2.pt\"),\n",
    "    word_char_tokenizer=word_char_tokenizer,\n",
    "    dataset=val_default_dataset,\n",
    "    generator_ctor=GreedyGenerator,\n",
    "    n_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8531223449447749"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_MMR =  get_mmr(default_predictions, val_default_targets)\n",
    "default_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_predictions_best_bigger = default_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_predictions_best_bigger_clean, _ = separate_out_vocab_all_crvs(default_predictions_best_bigger, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8784"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bool(el) for el in default_predictions_best_bigger_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9416/9416 [04:08<00:00, 37.90it/s]\n"
     ]
    }
   ],
   "source": [
    "default_predictions = weights_to_raw_predictions(\n",
    "    grid_name = \"default\",\n",
    "    model_getter=get_m1_smaller_model,\n",
    "    weights_path = os.path.join(MODELS_ROOT, \"m1_smaller/m1_smaller_v2_2023_11_11_17_43_35_0_33179_default_l2_1e_05_ls0_02.pt\"),\n",
    "    word_char_tokenizer=word_char_tokenizer,\n",
    "    dataset=val_default_dataset,\n",
    "    generator_ctor=GreedyGenerator,\n",
    "    n_workers=4\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_predictions_clean, _ = separate_out_vocab_all_crvs(default_predictions, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8449"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(bool(el) for el in default_predictions_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8221112999150383"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_MMR =  get_mmr(default_predictions, val_default_targets)\n",
    "default_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# grid_name = \"default\"\n",
    "# model_getter = get_m1_bigger_model\n",
    "# weights_path = os.path.join(MODELS_ROOT, \"m1_bigger/m1_bigger_v2__2023_11_11__13_17_50__0.13845_default_l2_0_ls0_switch_0.pt\")\n",
    "# model = model_getter(device, weights_path)\n",
    "# grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9416/9416 [05:02<00:00, 31.10it/s]\n"
     ]
    }
   ],
   "source": [
    "# default_predictions = predict_greedy_raw_multiproc(val_default_dataset,\n",
    "#                                                     grid_name_to_greedy_generator,\n",
    "#                                                     num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"extra\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2/m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 584/584 [00:18<00:00, 31.60it/s]\n"
     ]
    }
   ],
   "source": [
    "extra_predictions = predict_raw_mp(val_extra_dataset,\n",
    "                                   grid_name_to_greedy_generator,\n",
    "                                   num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.851027397260274"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_MMR = get_mmr(extra_predictions, val_extra_targets)\n",
    "extra_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_preds = merge_default_and_extra_preds(default_predictions, extra_predictions, val_default_dataset.grid_name_idxs, val_extra_dataset.grid_name_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets = None\n",
    "with open(os.path.join(DATA_ROOT, \"valid.ref\"), 'r', encoding='utf-8') as f:\n",
    "    all_targets = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8512"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_MMR = get_mmr(all_preds, all_targets)\n",
    "full_MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 365,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(len(el) for el in all_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "{\"m1_v2/best_model__2023_11_09__10_36_02__0.14229_default_switch_2_try_2.pt\": 0.8512107051826678,\n",
    " \"m1_v2/m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt\": 0.851027397260274,\n",
    " \n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__13_38_32__0.50552_default_l2_5e-05_ls0.045_switch_0.pt\": 0.810429056924384,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__16_36_38__0.49848_default_l2_5e-05_ls0.045_switch_0.pt\": 0.818500424808836,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_10__21_51_01__0.49382_default_l2_5e-05_ls0.045_switch_0.pt\": 0.8210492778249787,\n",
    " \n",
    " \"m1_bigger/m1_bigger_v2__2023_11_11__13_17_50__0.13845_default_l2_0_ls0_switch_0.pt\": 0.8512107051826678,\n",
    " \"m1_bigger/m1_bigger_v2__2023_11_11__14_29_37__0.13679_default_l2_0_ls0_switch_0.pt\": 0.8531223449447749,\n",
    " \n",
    " \"m1_smaller/m1_smaller_v2_2023_11_11_17_43_35_0_33179_default_l2_1e_05_ls0_02.pt\": 0.8221112999150383}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's create a greedy submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Set, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name = \"default\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2/m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}\n",
    "default_test_predictions = predict_raw_mp(test_default_dataset,\n",
    "                                          grid_name_to_greedy_generator,\n",
    "                                          num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 627/627 [00:20<00:00, 30.18it/s]\n"
     ]
    }
   ],
   "source": [
    "grid_name = \"extra\"\n",
    "model_getter = get_m1_model\n",
    "weights_path = os.path.join(MODELS_ROOT, \"m1_v2/m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt\")\n",
    "model = model_getter(device, weights_path)\n",
    "grid_name_to_greedy_generator = {grid_name: GreedyGenerator(model, word_char_tokenizer, device)}\n",
    "extra_test_predictions = predict_raw_mp(test_extra_dataset,\n",
    "                                        grid_name_to_greedy_generator,\n",
    "                                        num_workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_test_preds = merge_default_and_extra_preds(default_test_predictions, extra_test_predictions, test_default_dataset.grid_name_idxs, test_extra_dataset.grid_name_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = get_vocab_set(os.path.join(DATA_ROOT, \"voc.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_test_preds, invalid_test_preds = separate_out_vocab_all_crvs(all_test_preds, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['на'],\n",
       " ['что'],\n",
       " ['опоздания'],\n",
       " ['сколько'],\n",
       " [],\n",
       " ['не'],\n",
       " ['как'],\n",
       " ['садовод'],\n",
       " ['заметил'],\n",
       " ['ваги']]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_test_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "augment_list = None\n",
    "with open(r\"..\\data\\submissions\\sample_submission.csv\", 'r', encoding = 'utf-8') as f:\n",
    "    augment_lines = f.read().splitlines()\n",
    "augment_list = [line.split(\",\") for line in augment_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "augmented_test_preds = append_preds(clean_test_preds, augment_list, limit = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['на', 'неа', 'на', 'ненка'],\n",
       " ['что', 'часто', 'частого', 'чисто'],\n",
       " ['опоздания', 'опоздания', 'опозданиям', 'оприходования'],\n",
       " ['сколько', 'сколько', 'сокольского', 'свердловского'],\n",
       " ['дремать', 'дописать', 'донимать', 'дюрренматт'],\n",
       " ['не', 'неук', 'нк', 'ненка'],\n",
       " ['как', 'как', 'капак', 'капе'],\n",
       " ['садовод', 'спародировал', 'садовод', 'сурдоперевод'],\n",
       " ['заметил', 'знаменито', 'знаменитого', 'замерил'],\n",
       " ['ваги', 'ваенги', 'венгрии', 'ванги']]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "augmented_test_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_name = \"m1_v2__0.14229_deault__0.14301_extra__greedy.csv\"\n",
    "out_path = rf\"..\\data\\submissions\\{submission_name}\"\n",
    "create_submission(augmented_test_preds, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeamSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple, List\n",
    "def remove_beamsearch_probs(preds: List[List[Tuple[float, str]]]) -> List[List[str]]:\n",
    "    new_preds = []\n",
    "    for pred_line in preds:\n",
    "        new_preds_line = []\n",
    "        for _, word in pred_line:\n",
    "            new_preds_line.append(word)\n",
    "        new_preds.append(new_preds_line)\n",
    "    return new_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def patch_wrong_prediction_shape(prediciton):\n",
    "    return [pred_el[0] for pred_el in prediciton]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beamsearch Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_VAL_WORD_LEN = max(len(el) for el in all_targets)\n",
    "\n",
    "generator_kwargs = {\n",
    "    'max_steps_n': MAX_VAL_WORD_LEN+1,\n",
    "    'return_hypotheses_n': 7,\n",
    "    'beamsize': 6,\n",
    "    'normalization_factor': 0.5,\n",
    "    'verbose': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name_to_val_dataset = {\n",
    "    'default': val_default_dataset,\n",
    "    'extra': val_extra_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9416/9416 [41:23<00:00,  3.79it/s] \n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "bs_params = [\n",
    "    (\"default\", get_m1_bigger_model, \"m1_bigger/m1_bigger_v2__2023_11_12__14_51_49__0.13115__greed_acc_0.86034__default_l2_0_ls0_switch_2.pt\"),\n",
    "]\n",
    "\n",
    "\n",
    "for grid_name, model_getter, weights_f_name in bs_params:\n",
    "\n",
    "    bs_preds_path = os.path.join(\"../data/saved_beamsearch_validation_results/\",\n",
    "                                f\"{weights_f_name.replace('/', '__')}.pkl\")\n",
    "    \n",
    "    if os.path.exists(bs_preds_path):\n",
    "        print(f\"Path {bs_preds_path} exists. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    bs_predictions = weights_to_raw_predictions(\n",
    "        grid_name = grid_name,\n",
    "        model_getter=model_getter,\n",
    "        weights_path = os.path.join(MODELS_ROOT, weights_f_name),\n",
    "        word_char_tokenizer=word_char_tokenizer,\n",
    "        dataset=grid_name_to_val_dataset[grid_name],\n",
    "        generator_ctor=BeamGenerator,\n",
    "        n_workers=4,\n",
    "        generator_kwargs=generator_kwargs\n",
    "    )\n",
    "\n",
    "    with open(bs_preds_path, 'wb') as f:\n",
    "        pickle.dump(bs_predictions, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8929800339847141"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_name = \"m1_bigger__m1_bigger_v2__2023_11_12__14_51_49__0.13115__greed_acc_0.86034__default_l2_0_ls0_switch_2.pt.pkl\"\n",
    "bs_preds_path = os.path.join(\"../data/saved_beamsearch_validation_results/\",\n",
    "                                preds_name)\n",
    "with open(bs_preds_path, 'rb') as f:\n",
    "    default_valid_preds_bs = pickle.load(f)\n",
    "\n",
    "default_valid_preds_bs = patch_wrong_prediction_shape(default_valid_preds_bs)\n",
    "default_valid_preds_bs = remove_beamsearch_probs(default_valid_preds_bs)\n",
    "default_valid_preds_bs, _ = separate_out_vocab_all_crvs(default_valid_preds_bs, vocab_set)\n",
    "get_mmr(default_valid_preds_bs, val_default_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8876027397260277"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_name = \"m1_v2__m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt.pkl\"\n",
    "bs_preds_path = os.path.join(\"../data/saved_beamsearch_validation_results/\",\n",
    "                                preds_name)\n",
    "with open(bs_preds_path, 'rb') as f:\n",
    "    extra_valid_preds_bs = pickle.load(f)\n",
    "\n",
    "extra_valid_preds_bs = patch_wrong_prediction_shape(extra_valid_preds_bs)\n",
    "extra_valid_preds_bs = remove_beamsearch_probs(extra_valid_preds_bs)\n",
    "extra_valid_preds_bs, _ = separate_out_vocab_all_crvs(extra_valid_preds_bs, vocab_set)\n",
    "get_mmr(extra_valid_preds_bs, val_extra_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# {\n",
    "#     \"m1_smaller__m1_smaller_v2_2023_11_12_01_21_45_0_31891_default_l2_1e_05_ls0_02.pt.pkl\": 0.8811533559898118,\n",
    "#     \"m1_smaller__m1_smaller_v2_2023_11_12_08_17_33_0_31223_default_l2_1e_05_ls0_02.pt.pkl\": 0.8835960067969484,\n",
    "#     \"m1_bigger__m1_bigger_v2__2023_11_11__22_18_35__0.13542_default_l2_0_ls0_switch_1.pt.pkl\": 0.8900881478334822,\n",
    "#     \"m1_bigger__m1_bigger_v2__2023_11_11__15_53_07__0.13636_default_l2_0_ls0_switch_0.pt.pkl\": 0.8871590909090984,\n",
    "#     \"m1_bigger__m1_bigger_v2__2023_11_12__00_39_33__0.13297_default_l2_0_ls0_switch_1.pt.pkl\": 0.887674171622777,\n",
    "#     \"m1_v2__m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt.pkl\": 0.8877740016992428,\n",
    "    \n",
    "    \n",
    "#     \"m1_bigger__m1_bigger_v2__2023_11_11__16_45_33__0.13721_extra_l2_0_ls0_switch_0.pt.pkl\": 0.8864383561643838,\n",
    "#     \"m1_v2__m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt.pkl\": 0.8876027397260277\n",
    "    \n",
    "# }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name_to_ranged_bs_model_preds_paths = {\n",
    "    'default': [\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__14_51_49__0.13115__greed_acc_0.86034__default_l2_0_ls0_switch_2.pt.pkl\", #: 0.8929800339847141,\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__12_30_29__0.13121__greed_acc_0.86098__default_l2_0_ls0_switch_2.pt.pkl\", #: 0.8914698385726496,\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__22_18_35__0.13542_default_l2_0_ls0_switch_1.pt.pkl\",  #: 0.8900881478334822,\n",
    "        \"m1_v2__m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt.pkl\",  #: E 0.8877740016992428,\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__00_39_33__0.13297_default_l2_0_ls0_switch_1.pt.pkl\",  #: 0.887674171622777,\n",
    "        # \"m1_bigger__m1_bigger_v2__2023_11_11__15_53_07__0.13636_default_l2_0_ls0_switch_0.pt.pkl\",  #: 0.8871590909090984,\n",
    "        \"m1_smaller__m1_smaller_v2__2023_11_12__17_40_42__0.30909_default_l2_1e-05_ls0.02_switch_0.pt.pkl\",  # 0.8849384027187835\n",
    "        # \"m1_smaller__m1_smaller_v2_2023_11_12_08_17_33_0_31223_default_l2_1e_05_ls0_02.pt.pkl\",  #: 0.8835960067969484,\n",
    "        # \"m1_smaller__m1_smaller_v2_2023_11_12_01_21_45_0_31891_default_l2_1e_05_ls0_02.pt.pkl\",  #: 0.8811533559898118,\n",
    "        ],\n",
    "    'extra': [\n",
    "        \"m1_v2__m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__16_45_33__0.13721_extra_l2_0_ls0_switch_0.pt.pkl\"\n",
    "        ]\n",
    "}\n",
    "\n",
    "# Отранжированы по качесту beamsearch на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "default_idxs = val_default_dataset.grid_name_idxs\n",
    "extra_idxs = val_extra_dataset.grid_name_idxs \n",
    "\n",
    "grid_name_to_augmented_preds = {}\n",
    "\n",
    "for grid_name in ('default', 'extra'):\n",
    "    bs_pred_list = []\n",
    "\n",
    "    for f_name in grid_name_to_ranged_bs_model_preds_paths[grid_name]:\n",
    "        f_path = os.path.join(\"../data/saved_beamsearch_validation_results/\", f_name)\n",
    "        with open(f_path, 'rb') as f:\n",
    "            bs_pred_list.append(pickle.load(f))\n",
    "        \n",
    "    bs_pred_list = [patch_wrong_prediction_shape(bs_preds) for bs_preds in bs_pred_list] \n",
    "    bs_pred_list = [remove_beamsearch_probs(bs_preds) for bs_preds in bs_pred_list]\n",
    "    bs_pred_list = [separate_out_vocab_all_crvs(bs_preds, vocab_set)[0] for bs_preds in bs_pred_list]\n",
    "\n",
    "\n",
    "    augmented_preds = bs_pred_list.pop(0)\n",
    "\n",
    "    while bs_pred_list:\n",
    "        augmented_preds = append_preds(augmented_preds, bs_pred_list.pop(0))\n",
    "\n",
    "    grid_name_to_augmented_preds[grid_name] = augmented_preds\n",
    "\n",
    "\n",
    "full_preds = merge_default_and_extra_preds(\n",
    "    grid_name_to_augmented_preds['default'],\n",
    "    grid_name_to_augmented_preds['extra'],\n",
    "    default_idxs,\n",
    "    extra_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "n_preds_in_line_dict = defaultdict(int)\n",
    "\n",
    "for line in full_preds:\n",
    "    n_preds_in_line_dict[len(line)] += 1\n",
    "\n",
    "print(n_preds_in_line_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_targets = None\n",
    "with open(os.path.join(DATA_ROOT, \"valid.ref\"), 'r', encoding='utf-8') as f:\n",
    "    all_targets = f.read().splitlines() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_mmr(full_preds, all_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "grid_name_to_ranged_bs_model_preds_paths = {\n",
    "    'default': [\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__22_18_35__0.13542_default_l2_0_ls0_switch_1.pt.pkl\",#: 0.8900881478334822,\n",
    "        \"m1_v2__m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt.pkl\",#: 0.8877740016992428,\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__00_39_33__0.13297_default_l2_0_ls0_switch_1.pt.pkl\",#: 0.887674171622777,\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__15_53_07__0.13636_default_l2_0_ls0_switch_0.pt.pkl\",#: 0.8871590909090984,\n",
    "        \"m1_smaller__m1_smaller_v2_2023_11_12_08_17_33_0_31223_default_l2_1e_05_ls0_02.pt.pkl\",#: 0.8835960067969484,\n",
    "        \"m1_smaller__m1_smaller_v2_2023_11_12_01_21_45_0_31891_default_l2_1e_05_ls0_02.pt.pkl\",#: 0.8811533559898118,\n",
    "        ],\n",
    "    'extra': [\n",
    "        \"m1_v2__m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__16_45_33__0.13721_extra_l2_0_ls0_switch_0.pt.pkl\"\n",
    "        ]\n",
    "}\n",
    "```\n",
    "\n",
    "0.8936010000000082\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "grid_name_to_ranged_bs_model_preds_paths = {\n",
    "    'default': [\n",
    "        \"m1_v2__m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt.pkl\",#: 0.8877740016992428,\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__22_18_35__0.13542_default_l2_0_ls0_switch_1.pt.pkl\",#: 0.8900881478334822,\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__00_39_33__0.13297_default_l2_0_ls0_switch_1.pt.pkl\",#: 0.887674171622777,\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__15_53_07__0.13636_default_l2_0_ls0_switch_0.pt.pkl\",#: 0.8871590909090984,\n",
    "        \"m1_smaller__m1_smaller_v2_2023_11_12_08_17_33_0_31223_default_l2_1e_05_ls0_02.pt.pkl\",#: 0.8835960067969484,\n",
    "        \"m1_smaller__m1_smaller_v2_2023_11_12_01_21_45_0_31891_default_l2_1e_05_ls0_02.pt.pkl\",#: 0.8811533559898118,\n",
    "        ],\n",
    "    'extra': [\n",
    "        \"m1_v2__m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__16_45_33__0.13721_extra_l2_0_ls0_switch_0.pt.pkl\"\n",
    "        ]\n",
    "}\n",
    "```\n",
    "\n",
    "0.892801000000009\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "``` python\n",
    "grid_name_to_ranged_bs_model_preds_paths = {\n",
    "    'default': [\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__22_18_35__0.13542_default_l2_0_ls0_switch_1.pt.pkl\",#: 0.8900881478334822,\n",
    "        \"m1_v2__m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt.pkl\",#: 0.8877740016992428,\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__00_39_33__0.13297_default_l2_0_ls0_switch_1.pt.pkl\",#: 0.887674171622777,\n",
    "        \"m1_smaller__m1_smaller_v2_2023_11_12_08_17_33_0_31223_default_l2_1e_05_ls0_02.pt.pkl\",#: 0.8835960067969484,\n",
    "        \"m1_smaller__m1_smaller_v2_2023_11_12_01_21_45_0_31891_default_l2_1e_05_ls0_02.pt.pkl\",#: 0.8811533559898118,\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__15_53_07__0.13636_default_l2_0_ls0_switch_0.pt.pkl\",#: 0.8871590909090984,\n",
    "        ],\n",
    "    'extra': [\n",
    "        \"m1_v2__m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__16_45_33__0.13721_extra_l2_0_ls0_switch_0.pt.pkl\"\n",
    "        ]\n",
    "}\n",
    "\n",
    "# должны ранжироваться по качесту beamsearch на валидации\n",
    "```\n",
    "\n",
    "0.8936000000000084"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Beamsearch test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_WORD_LEN = 36\n",
    "\n",
    "generator_kwargs = {\n",
    "    'max_steps_n': MAX_WORD_LEN - 1,\n",
    "    'return_hypotheses_n': 7,\n",
    "    'beamsize': 6,\n",
    "    'normalization_factor': 0.5,\n",
    "    'verbose': False\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name_to_test_dataset = {\n",
    "    'default': test_default_dataset,\n",
    "    'extra': test_extra_dataset\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 627/627 [06:02<00:00,  1.73it/s]\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "bs_params = [\n",
    "    (\"extra\", get_m1_bigger_model, \"m1_bigger/m1_bigger_v2__2023_11_12__02_27_14__0.13413_extra_l2_0_ls0_switch_1.pt\"),\n",
    "\n",
    "    # \"m1_smaller__m1_smaller_v2_2023_11_12_08_17_33_0_31223_default_l2_1e_05_ls0_02.pt.pkl\": 0.8835960067969484,\n",
    "    # \"m1_bigger__m1_bigger_v2__2023_11_11__15_53_07__0.13636_default_l2_0_ls0_switch_0.pt.pkl\": 0.8871590909090984,\n",
    "    # \"m1_bigger__m1_bigger_v2__2023_11_11__16_45_33__0.13721_extra_l2_0_ls0_switch_0.pt.pkl\": 0.8864383561643838,\n",
    "]\n",
    "\n",
    "\n",
    "for grid_name, model_getter, weights_f_name in bs_params:\n",
    "\n",
    "    bs_preds_path = os.path.join(\"../data/saved_beamsearch_results/\",\n",
    "                                f\"{weights_f_name.replace('/', '__')}.pkl\")\n",
    "    \n",
    "    if os.path.exists(bs_preds_path):\n",
    "        print(f\"Path {bs_preds_path} exists. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    bs_predictions = weights_to_raw_predictions(\n",
    "        grid_name = grid_name,\n",
    "        model_getter=model_getter,\n",
    "        weights_path = os.path.join(MODELS_ROOT, weights_f_name),\n",
    "        word_char_tokenizer=word_char_tokenizer,\n",
    "        dataset=grid_name_to_test_dataset[grid_name],\n",
    "        generator_ctor=BeamGenerator,\n",
    "        n_workers=4,\n",
    "        generator_kwargs=generator_kwargs\n",
    "    )\n",
    "\n",
    "    with open(bs_preds_path, 'wb') as f:\n",
    "        pickle.dump(bs_predictions, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9373, 9193)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# len(clean_default_test_predictions), sum(bool(el) for el in clean_default_test_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_set = get_vocab_set(os.path.join(DATA_ROOT, \"voc.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {4: 7404, 3: 1032, 2: 840, 1: 577, 0: 147})\n"
     ]
    }
   ],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# n_preds_in_line_dict = defaultdict(int)\n",
    "\n",
    "# for line in clean_test_predictions:\n",
    "#     n_preds_in_line_dict[len(line)] += 1\n",
    "\n",
    "# print(n_preds_in_line_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_preds_path = os.path.join(DATA_ROOT, \"test_raw_pred___best_model__2023_11_04__18_31_37__0.02530_default_switch_2.pt__best_model__2023_11_05__07_55_13__0.02516_extra_switch_2__with_pad_cutting.pt.pkl\")\n",
    "with open(old_preds_path, 'rb') as f:\n",
    "    old_preds_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_preds_list = remove_beamsearch_probs(old_preds_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "old_preds_list_valid, old_preds_list_invalid = separate_out_vocab_all_crvs(old_preds_list, vocab_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "# submission_name = \"default__m1_bigger_13679__m1_v2__14229___extra__14301___with_baseline__beam.csv\"\n",
    "# out_path = rf\"..\\data\\submissions\\{submission_name}\"\n",
    "# create_submission(clean_test_baseline_augmented, out_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id 1\n",
    "\n",
    "```\n",
    "grid_name_to_ranged_bs_model_preds_paths = {\n",
    "    'default': [\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__12_30_29__0.13121__greed_acc_0.86098__default_l2_0_ls0_switch_2.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__22_18_35__0.13542_default_l2_0_ls0_switch_1.pt.pkl\",\n",
    "        \"m1_v2__m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__00_39_33__0.13297_default_l2_0_ls0_switch_1.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__14_29_37__0.13679_default_l2_0_ls0_switch_0.pt.pkl\",\n",
    "        \n",
    "    ],\n",
    "    'extra': [\"m1_v2__m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt.pkl\"]\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id 2\n",
    "\n",
    "```\n",
    "grid_name_to_ranged_bs_model_preds_paths = {\n",
    "    'default': [\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__12_30_29__0.13121__greed_acc_0.86098__default_l2_0_ls0_switch_2.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__22_18_35__0.13542_default_l2_0_ls0_switch_1.pt.pkl\",\n",
    "        \"m1_v2__m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__00_39_33__0.13297_default_l2_0_ls0_switch_1.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__14_29_37__0.13679_default_l2_0_ls0_switch_0.pt.pkl\",\n",
    "        \n",
    "    ],\n",
    "    'extra': [\n",
    "        \"m1_v2__m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__02_27_14__0.13413_extra_l2_0_ls0_switch_1.pt.pkl\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# должны ранжироваться по качесту beamsearch на валидации\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "id 3\n",
    "\n",
    "```python\n",
    "grid_name_to_ranged_bs_model_preds_paths = {\n",
    "    'default': [\n",
    "        \"m1_bigger_m1_bigger_v2_2023_11_12_14_51_49_0_13115_greed_acc_0_86034.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__12_30_29__0.13121__greed_acc_0.86098__default_l2_0_ls0_switch_2.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__22_18_35__0.13542_default_l2_0_ls0_switch_1.pt.pkl\",\n",
    "        \"m1_v2__m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__00_39_33__0.13297_default_l2_0_ls0_switch_1.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__14_29_37__0.13679_default_l2_0_ls0_switch_0.pt.pkl\",\n",
    "        \n",
    "    ],\n",
    "    'extra': [\n",
    "        \"m1_v2__m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__02_27_14__0.13413_extra_l2_0_ls0_switch_1.pt.pkl\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# должны ранжироваться по качесту beamsearch на валидации\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_name_to_ranged_bs_model_preds_paths = {\n",
    "    'default': [\n",
    "        \"m1_bigger_m1_bigger_v2_2023_11_12_14_51_49_0_13115_greed_acc_0_86034.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__12_30_29__0.13121__greed_acc_0.86098__default_l2_0_ls0_switch_2.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__22_18_35__0.13542_default_l2_0_ls0_switch_1.pt.pkl\",\n",
    "        \"m1_v2__m1_v2__2023_11_09__10_36_02__0.14229_default_switch_0.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__00_39_33__0.13297_default_l2_0_ls0_switch_1.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_11__14_29_37__0.13679_default_l2_0_ls0_switch_0.pt.pkl\",\n",
    "        \n",
    "    ],\n",
    "    'extra': [\n",
    "        \"m1_v2__m1_v2__2023_11_09__17_47_40__0.14301_extra_l2_1e-05_switch_0.pt.pkl\",\n",
    "        \"m1_bigger__m1_bigger_v2__2023_11_12__02_27_14__0.13413_extra_l2_0_ls0_switch_1.pt.pkl\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# должны ранжироваться по качесту beamsearch на валидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_idxs = test_default_dataset.grid_name_idxs\n",
    "extra_idxs = test_extra_dataset.grid_name_idxs \n",
    "\n",
    "grid_name_to_augmented_preds = {}\n",
    "\n",
    "for grid_name in ('default', 'extra'):\n",
    "    bs_pred_list = []\n",
    "\n",
    "    for f_name in grid_name_to_ranged_bs_model_preds_paths[grid_name]:\n",
    "        f_path = os.path.join(\"../data/saved_beamsearch_results/\", f_name)\n",
    "        with open(f_path, 'rb') as f:\n",
    "            bs_pred_list.append(pickle.load(f))\n",
    "        \n",
    "    bs_pred_list = [patch_wrong_prediction_shape(bs_preds) for bs_preds in bs_pred_list] \n",
    "    bs_pred_list = [remove_beamsearch_probs(bs_preds) for bs_preds in bs_pred_list]\n",
    "    bs_pred_list = [separate_out_vocab_all_crvs(bs_preds, vocab_set)[0] for bs_preds in bs_pred_list]\n",
    "\n",
    "\n",
    "    augmented_preds = bs_pred_list.pop(0)\n",
    "\n",
    "    while bs_pred_list:\n",
    "        augmented_preds = append_preds(augmented_preds, bs_pred_list.pop(0))\n",
    "\n",
    "    grid_name_to_augmented_preds[grid_name] = augmented_preds\n",
    "\n",
    "\n",
    "full_preds = merge_default_and_extra_preds(\n",
    "    grid_name_to_augmented_preds['default'],\n",
    "    grid_name_to_augmented_preds['extra'],\n",
    "    default_idxs,\n",
    "    extra_idxs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'int'>, {4: 8188, 3: 706, 2: 606, 1: 407, 0: 93})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "n_preds_in_line_dict = defaultdict(int)\n",
    "\n",
    "for line in full_preds:\n",
    "    n_preds_in_line_dict[len(line)] += 1\n",
    "\n",
    "print(n_preds_in_line_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_preds = None\n",
    "with open(r\"..\\data\\submissions\\sample_submission.csv\", 'r', encoding = 'utf-8') as f:\n",
    "    baseline_preds = f.read().splitlines()\n",
    "baseline_preds = [line.split(\",\") for line in augment_lines]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_preds = append_preds(full_preds, baseline_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_submission(full_preds,\n",
    "                  f\"../data/submissions/id3_with_baseline_without_old_preds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_preds_augmentations = [\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
